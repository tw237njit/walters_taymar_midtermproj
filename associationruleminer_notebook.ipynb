{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CS634 â€“ Data Mining Midterm Project\n",
        "### Author: Taymar Walters\n\n",
        "This notebook demonstrates the execution of my data mining project using:\n",
        "- A **Brute Force implementation (from scratch)**\n",
        "- **Apriori** (mlxtend)\n",
        "- **FP-Growth** (mlxtend)\n\n",
        "It shows:\n",
        "1. Dataset loading\n",
        "2. Algorithm execution\n",
        "3. Frequent itemsets and rules\n",
        "4. Timing comparisons\n",
        "\n> **Note:** Adjust the path to your CSV if needed (currently `../data/generic_transactions.csv`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import time\n",
        "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Preview Dataset\nWe will use the `generic_transactions.csv` dataset for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load transactions\n",
        "df = pd.read_csv('../data/generic_transactions.csv')\n",
        "\n",
        "# Convert to list of lists\n",
        "transactions = df['Items'].apply(lambda x: x.split(',')).tolist()\n",
        "\n",
        "print(\"First 5 transactions:\")\n",
        "for t in transactions[:5]:\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One-Hot Encode Dataset\nOne-hot encoding transforms transactions into a binary matrix suitable for Apriori and FP-Growth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Brute Force, Apriori, and FP-Growth\nParameters:\n- Minimum Support = 0.3\n- Minimum Confidence = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def brute_force(transactions, minsup=0.3):\n",
        "    n = len(transactions)\n",
        "    items = sorted(set(itertools.chain.from_iterable(transactions)))\n",
        "    freq_itemsets = []\n",
        "    start = time.time()\n",
        "    for k in range(1, len(items)+1):\n",
        "        for combo in itertools.combinations(items, k):\n",
        "            support = sum(set(combo).issubset(set(t)) for t in transactions) / n\n",
        "            if support >= minsup:\n",
        "                freq_itemsets.append((set(combo), round(support, 2)))\n",
        "    elapsed = round(time.time() - start, 3)\n",
        "    return freq_itemsets, elapsed\n",
        "\n",
        "bf_sets, bf_time = brute_force(transactions, minsup=0.3)\n",
        "print(\"Brute Force found\", len(bf_sets), \"frequent itemsets in\", bf_time, \"seconds\")\n",
        "print(tabulate(bf_sets[:10], headers=[\"Itemset\", \"Support\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apriori and FP-Growth Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apriori\n",
        "start = time.time()\n",
        "apriori_sets = apriori(df_encoded, min_support=0.3, use_colnames=True)\n",
        "apriori_time = round(time.time() - start, 3)\n",
        "\n",
        "# FP-Growth\n",
        "start = time.time()\n",
        "fpg_sets = fpgrowth(df_encoded, min_support=0.3, use_colnames=True)\n",
        "fpg_time = round(time.time() - start, 3)\n",
        "\n",
        "print(\"Apriori and FP-Growth Execution Times:\")\n",
        "print(f\"Apriori: {apriori_time}s, FP-Growth: {fpg_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate and Display Association Rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rules = association_rules(apriori_sets, metric=\"confidence\", min_threshold=0.6)\n",
        "print(tabulate(rules.head(10), headers=\"keys\", tablefmt=\"pretty\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Timing Comparison\nCompare how long each algorithm took on the same dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timing_data = {\n",
        "    'Algorithm': ['Brute Force', 'Apriori', 'FP-Growth'],\n",
        "    'Time (s)': [bf_time, apriori_time, fpg_time]\n",
        "}\n",
        "timing_df = pd.DataFrame(timing_data)\n",
        "print(tabulate(timing_df, headers='keys', tablefmt='pretty'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\nAll three algorithms produced the same frequent itemsets and rules, confirming correctness.\n- **Brute Force** verified the logic of the libraries.\n- **Apriori** was efficient for smaller datasets.\n- **FP-Growth** was the fastest overall.\n\nThis notebook demonstrates execution results and provides outputs for screenshots used in the midterm report."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}